{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install obspy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_535ZaHig7F",
        "outputId": "d8eae577-ba74-4d14-e714-c9438a7ff2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: obspy in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from obspy) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from obspy) (1.13.1)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from obspy) (3.7.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from obspy) (4.9.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from obspy) (71.0.4)\n",
            "Requirement already satisfied: sqlalchemy<2 in /usr/local/lib/python3.10/dist-packages (from obspy) (1.4.54)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from obspy) (4.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from obspy) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (2.8.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2->obspy) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->obspy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->obspy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->obspy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->obspy) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->obspy) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cexidJvR_8xw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import spectrogram, welch\n",
        "from obspy.signal.invsim import cosine_taper\n",
        "from obspy.signal.filter import highpass\n",
        "from obspy.signal.trigger import classic_sta_lta, plot_trigger, trigger_onset, recursive_sta_lta\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "zip_file_path = '/content/drive/MyDrive/space_apps_2024_seismic_detection.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    extracted_files = zip_ref.extractall('/content')"
      ],
      "metadata": {
        "id": "nTQCQkstDJUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lunar_training_folder_path = './space_apps_2024_seismic_detection/data/lunar/training/data/S12_GradeA'\n",
        "lunar_training_csv_files = glob.glob(os.path.join(lunar_training_folder_path, '*.csv'))\n",
        "\n",
        "lunar_test_folder_path = './space_apps_2024_seismic_detection/data/lunar/test/data/S16_GradeA'\n",
        "lunar_test_csv_files = glob.glob(os.path.join(lunar_test_folder_path, '*.csv'))\n",
        "\n",
        "lunar_catalog_csv_file = './space_apps_2024_seismic_detection/data/lunar/training/catalogs/apollo12_catalog_GradeA_final.csv'\n"
      ],
      "metadata": {
        "id": "0LwqMUflBeN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_true_triggers(file_path):\n",
        "    labeled_data = pd.read_csv(file_path)\n",
        "    true_triggers = {}\n",
        "    for _, row in labeled_data.iterrows():\n",
        "        filename = row['filename'].removesuffix('.csv')\n",
        "        if filename not in true_triggers:\n",
        "            true_triggers[filename] = []\n",
        "        true_triggers[filename].append(row['time_rel(sec)'])\n",
        "    return true_triggers"
      ],
      "metadata": {
        "id": "OleX-p4zI_mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def implement_STA_LTA(df, sta_len, lta_len, thr_on, thr_off):\n",
        "    time_rel = df['time_rel(sec)'].values\n",
        "    velocity = df['velocity(m/s)'].values\n",
        "    dt = time_rel[1] - time_rel[0]\n",
        "    sampling_rate = 1 / dt\n",
        "\n",
        "    cft = classic_sta_lta(velocity, int(sta_len * sampling_rate), int(lta_len * sampling_rate))\n",
        "    on_off = np.array(trigger_onset(cft, thr_on, thr_off))\n",
        "    detected_triggers = [time_rel[triggers[0]] for triggers in on_off if len(triggers) > 0]\n",
        "\n",
        "    print(f\"Detected triggers: {detected_triggers}\")\n",
        "    return detected_triggers"
      ],
      "metadata": {
        "id": "5rmiOuGrCcgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOLERANCE = 1000\n",
        "\n",
        "def match_triggers(true_triggers, detected_triggers):\n",
        "    matches = []\n",
        "    used_detected = set()\n",
        "\n",
        "    for true_trigger in true_triggers:\n",
        "        for i, detected_trigger in enumerate(detected_triggers):\n",
        "            if i not in used_detected and abs(detected_trigger - true_trigger) <= TOLERANCE:\n",
        "                matches.append((true_trigger, detected_trigger))\n",
        "                used_detected.add(i)\n",
        "                break\n",
        "\n",
        "    return matches\n",
        "\n",
        "\n",
        "def score_function(true_triggers, detected_triggers):\n",
        "    # Match detected triggers to true triggers\n",
        "    matches = match_triggers(true_triggers, detected_triggers)\n",
        "\n",
        "    # Calculate precision, recall, and F1-score\n",
        "    num_true = len(true_triggers)\n",
        "    num_detected = len(detected_triggers)\n",
        "    num_matches = len(matches)\n",
        "\n",
        "    precision = num_matches / num_detected if num_detected > 0 else 0\n",
        "    recall = num_matches / num_true if num_true > 0 else 0\n",
        "    if precision + recall > 0:\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    else:\n",
        "        f1_score = 0\n",
        "\n",
        "    return f1_score"
      ],
      "metadata": {
        "id": "JBhRSbBbE4eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT TOUCH, LOADING FROM FOLDER\n",
        "all_lunar_training_data = []\n",
        "for file_path in lunar_training_csv_files:\n",
        "    all_lunar_training_data.append({'df': pd.read_csv(file_path), 'filename': file_path.split('/')[-1].removesuffix('.csv')})\n",
        "lunar_true_triggers = pd.read_csv(lunar_catalog_csv_file)"
      ],
      "metadata": {
        "id": "9Zx2Ek5GE_Qx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "118fe667-16b8-4349-c23a-07772fd5b2fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-14-fab1c6258496>\", line 4, in <cell line: 3>\n",
            "    all_lunar_training_data.append({'df': pd.read_csv(file_path), 'filename': file_path.split('/')[-1].removesuffix('.csv')})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
            "    return parser.read(nrows)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
            "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
            "    chunks = self._reader.read_low_memory(nrows)\n",
            "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
            "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
            "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
            "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
            "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
            "pandas.errors.ParserError: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'ParserError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1624, in getframeinfo\n",
            "    lines, lnum = findsource(frame)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 182, in findsource\n",
            "    lines = linecache.getlines(file, globals_dict)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 396, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 365, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 323, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-fab1c6258496>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlunar_training_csv_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mall_lunar_training_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'df'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'filename'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremovesuffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlunar_true_triggers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlunar_catalog_csv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ParserError' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_function(params):\n",
        "    sta_len, lta_len, thr_on, thr_off = params\n",
        "    total_f1 = 0\n",
        "\n",
        "    for quak_file in all_lunar_training_data:\n",
        "        print(f\"Processing: {quak_file['filename']}\")\n",
        "        detected_triggers = implement_STA_LTA(quak_file['df'], sta_len, lta_len, thr_on, thr_off)\n",
        "\n",
        "        # show_sound_plot(quak_file['filename'], detected_triggers)\n",
        "        f1 = score_function(true_triggers.loc[true_triggers['filename'] == quak_file['filename']]['time_rel(sec)'], detected_triggers)\n",
        "        total_f1 += f1\n",
        "\n",
        "    return -total_f1\n",
        "\n",
        "def evaluate_individual(individual):\n",
        "    sta_len, lta_len, thr_on, thr_off = individual\n",
        "    total_score = 0\n",
        "\n",
        "    # Loop over each file in wave_files\n",
        "    for file in wave_files:\n",
        "        df = file['df']\n",
        "        detected_triggers = implement_STA_LTA(df, sta_len, lta_len, thr_on, thr_off)\n",
        "        total_score += score_function(detected_triggers, ground_truth)\n",
        "\n",
        "    return -total_score,  # Return as a tuple, only difference from above, used for the evolutionary model"
      ],
      "metadata": {
        "id": "iluPGO3UJGpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bayse optimizer\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real\n",
        "search_space = [\n",
        "    Real(0.1, 10, name='sta_len'),\n",
        "    Real(10, 100, name='lta_len'),\n",
        "    Real(1.0, 3.0, name='thr_on'),\n",
        "    Real(0.5, 2.0, name='thr_off')\n",
        "]\n",
        "\n",
        "result = gp_minimize(objective_function, search_space, n_calls=50)\n",
        "\n",
        "best_params = result.x\n",
        "print(f\"Best parameters for Bayse optimizer: {best_params}\")"
      ],
      "metadata": {
        "id": "T_awgo-rAAKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient optimizer\n",
        "from scipy.optimize import minimize\n",
        "initial_guess = [1.0, 20.0, 2.0, 1.0]\n",
        "\n",
        "bounds = [(0.1, 10), (10, 100), (1.0, 3.0), (0.5, 2.0)]\n",
        "\n",
        "result = minimize(objective, initial_guess, bounds=bounds, method='L-BFGS-B')\n",
        "\n",
        "best_params = result.x\n",
        "print(f\"Best parameters for Gradient optimizer: {best_params}\")"
      ],
      "metadata": {
        "id": "kR2Xq0AzfH72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evolutionary optimizer\n",
        "from deap import base, creator, tools, algorithms\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_sta_len\", np.random.uniform, 0.1, 10)\n",
        "toolbox.register(\"attr_lta_len\", np.random.uniform, 10, 100)\n",
        "toolbox.register(\"attr_thr_on\", np.random.uniform, 1.0, 3.0)\n",
        "toolbox.register(\"attr_thr_off\", np.random.uniform, 0.5, 2.0)\n",
        "\n",
        "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "                 (toolbox.attr_sta_len, toolbox.attr_lta_len, toolbox.attr_thr_on, toolbox.attr_thr_off), n=1)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
        "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.1, indpb=0.2)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "toolbox.register(\"evaluate\", evaluate_individual)\n",
        "\n",
        "# Create initial population\n",
        "population = toolbox.population(n=50)\n",
        "\n",
        "# Perform evolutionary algorithm optimization\n",
        "algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=40, verbose=True)\n",
        "\n",
        "# Get the best individual\n",
        "best_individual = tools.selBest(population, 1)[0]\n",
        "print(f\"Best parameters for evolutionary model: {best_individual}\")"
      ],
      "metadata": {
        "id": "y9LYpLi0fICA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{'sta_len': 220, 'lta_len': 700, 'thr_on': 3.0, 'thr_off': 1.3}\n",
        "# optimize_parameters(all_lunar_training_data, lunar_true_triggers, tolerance=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJbx4ushJLdo",
        "outputId": "c8e53b8c-88f3-413a-82a4-e37ee8b5e3b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sta_len': 220, 'lta_len': 700, 'thr_on': 3.0, 'thr_off': 1.3}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_sound_plot(filename, x_values=None):\n",
        "    df = pd.read_csv(f'{lunar_test_folder_path}/{filename}.csv')\n",
        "    time_rel = df['time_rel(sec)'].values\n",
        "    velocity = df['velocity(m/s)']\n",
        "    fig, ax = plt.subplots(1,1,figsize=(10,3))\n",
        "    ax.plot(time_rel, velocity)\n",
        "    ax.set_xlim([min(time_rel),max(time_rel)])\n",
        "\n",
        "    if x_values is not None:\n",
        "        if isinstance(x_values, list):  # Check if x_values is a list\n",
        "            for x in x_values:\n",
        "                ax.axvline(x=x, color='red', linestyle='--', label=f'x = {x}')\n",
        "        else:  # If it's not a list, treat it as a single value\n",
        "            ax.axvline(x=x_values, color='red', linestyle='--', label=f'x = {x_values}')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "OvNkNeJJIC-p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}